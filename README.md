# Lab 4 – Model Training and Versioning with GitHub Actions

This lab automates the training and versioning of a machine learning model using GitHub Actions.  
Whenever a change is pushed to the main branch, a workflow is triggered to retrain the model, evaluate it, and store versioned artifacts in the repository.

---

## Objective

The primary goal of this lab is to demonstrate:
- How to automate an ML workflow using GitHub Actions
- How to version trained models and performance metrics
- How continuous integration practices can be applied to machine learning

---

## Implementation Summary

A **RandomForest Classifier** is trained on the **Wine dataset** from `scikit-learn`.  
The repository includes two automated pipelines:

1️⃣ **Model Retraining Workflow**
- Installs dependencies
- Trains the model on push
- Evaluates performance (Accuracy & Macro-F1)
- Saves timestamped artifacts into:
  - `models/` – Serialized model files
  - `metrics/` – Metric logs in JSON format
- Commits these artifacts back to the repository for version control

2️⃣ **Model Calibration Workflow**
- Calibrates predicted probabilities using the latest trained model
- Logs calibration performance
- Stores calibrated model versions and metrics

---

## Repository Structure

.
├── src/
│ ├── train_model.py
│ ├── evaluate_model.py
│ └── calibrate_model.py
├── test/
├── .github/
│ └── workflows/
│ ├── model_retraining_on_push.yml
│ ├── model_calibration_on_push.yml
│ └── model_calibration.yml
├── models/ # generated by workflow
├── metrics/ # generated by workflow
└── requirements.txt

